{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import uuid\n",
    "\n",
    "import chromadb\n",
    "from chromadb.config import Settings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders.confluence import ConfluenceLoader\n",
    "\n",
    "from modules.indexing import load_docs, split_documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set env vars for confluence wiki\n",
    "CONFLUENCE_PAT = os.getenv(\"CONFLUENCE_PAT\")\n",
    "CONFLUENCE_SPACE_KEY = os.getenv(\"CONFLUENCE_SPACE_KEY\")\n",
    "CONFLUENCE_URL = os.getenv(\"CONFLUENCE_URL\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set env vars for indexing\n",
    "CHUNK_SIZE = 800\n",
    "CHUNK_OVERLAP = 160\n",
    "# collection names in chroma will be based on the chunk size\n",
    "# thus you can experiment retrieving chunks of differnt size\n",
    "COLLECTION_NAME = f\"{CHUNK_SIZE}_{CONFLUENCE_SPACE_KEY}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading and splitting documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize Confluence document loader and \n",
    "# load documents from Confluence Wiki\n",
    "loader = ConfluenceLoader(\n",
    "    url=CONFLUENCE_URL,\n",
    "    token=CONFLUENCE_PAT,\n",
    "    cloud=False,\n",
    "    space_key=CONFLUENCE_SPACE_KEY,\n",
    "    include_attachments=False,\n",
    ")\n",
    "docs = load_docs(loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize splitter and split docs into chunks\n",
    "splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=CHUNK_SIZE, chunk_overlap=CHUNK_OVERLAP, add_start_index=True\n",
    ")\n",
    "chunks = split_documents(splitter, docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  a client that connects to a local chromadb server\n",
    "chroma_settings = Settings(allow_reset=True)\n",
    "chroma_client = chromadb.HttpClient(\n",
    "    settings=chroma_settings,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate and save embeddings in ChromaDB\n",
    "\n",
    "Choose one of the options for creating embeddings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AWS Bedrock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.embeddings.bedrock import BedrockEmbeddings\n",
    "embeddings_function = BedrockEmbeddings(\n",
    "    credentials_profile_name=os.getenv(\"AWS_CREDENTIALS_PROFILE_NAME\"),\n",
    "    region_name=os.getenv(\"AWS_REGION_NAME\", \"eu-central-1\"),\n",
    "    model_id=os.getenv(\"AWS_EMBEDDING_MODEL_ID\", \"amazon.titan-text-express-v1\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ollama embeddings\n",
    "\n",
    "- [Blog post about embedding models (by ollama)](https://ollama.com/blog/embedding-models)\n",
    "- [Ollama embedding model (langchain docs)](https://python.langchain.com/docs/integrations/text_embedding/ollama/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.embeddings.ollama import OllamaEmbeddings\n",
    "\n",
    "OLLAMA_EMBEDDING_MODEL = os.getenv(\"OLLAMA_EMBEDDING_MODEL\", \"mxbai-embed-large\")\n",
    "embeddings_function = OllamaEmbeddings(model=OLLAMA_EMBEDDING_MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collection = chroma_client.get_or_create_collection(name=COLLECTION_NAME)\n",
    "if collection.count() <= 0:\n",
    "    # store each document in a vector embedding database\n",
    "    for d in chunks:\n",
    "        response = embeddings_function.embed_query(d.page_content)\n",
    "        collection.add(\n",
    "            ids=[str(uuid.uuid1())],\n",
    "            embeddings=[response],\n",
    "            documents=[d.page_content],\n",
    "            metadatas=[d.metadata]\n",
    "        )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
